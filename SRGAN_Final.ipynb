{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRGAN - Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5OZ5GBZaUYa"
      },
      "source": [
        "!wget https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
        "!unzip DIV2K_train_HR.zip \n",
        "!wget https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip\n",
        "!unzip DIV2K_valid_HR.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI0KcjC3auG4"
      },
      "source": [
        "import torch\n",
        "import torchvision.utils as utils\n",
        "import math\n",
        "import os\n",
        "from os import listdir\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjX6tw0pa61z"
      },
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "from os.path import join\n",
        "from PIL import Image\n",
        "from torchvision.transforms import Compose, RandomCrop, ToTensor, ToPILImage, CenterCrop, Resize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0tpRB2Jdys4"
      },
      "source": [
        "def is_image_file(filename):\n",
        "    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])\n",
        "\n",
        "\n",
        "def calculate_valid_crop_size(crop_size, upscale_factor):\n",
        "    return crop_size - (crop_size % upscale_factor)\n",
        "\n",
        "def train_hr_transform(crop_size):\n",
        "    return Compose([\n",
        "        RandomCrop(crop_size),\n",
        "        ToTensor(),\n",
        "    ])    \n",
        "\n",
        "def train_lr_transform(crop_size, upscale_factor):\n",
        "    return Compose([\n",
        "        ToPILImage(),\n",
        "        Resize(crop_size // upscale_factor, interpolation=Image.BICUBIC),\n",
        "        ToTensor()\n",
        "    ])\n",
        "\n",
        "\n",
        "def display_transform():\n",
        "    return Compose([\n",
        "        ToPILImage(),\n",
        "        Resize(400),\n",
        "        CenterCrop(400),\n",
        "        ToTensor()\n",
        "    ])\n",
        "\n",
        "\n",
        "class TrainDatasetFromFolder(Dataset):\n",
        "    def __init__(self, dataset_dir, crop_size, upscale_factor):\n",
        "        super(TrainDatasetFromFolder, self).__init__()\n",
        "        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n",
        "        crop_size = calculate_valid_crop_size(crop_size, upscale_factor)\n",
        "        self.hr_transform = train_hr_transform(crop_size)\n",
        "        self.lr_transform = train_lr_transform(crop_size, upscale_factor)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        hr_image = self.hr_transform(Image.open(self.image_filenames[index]))\n",
        "        lr_image = self.lr_transform(hr_image)\n",
        "        return lr_image, hr_image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "\n",
        "class ValDatasetFromFolder(Dataset):\n",
        "    def __init__(self, dataset_dir, upscale_factor):\n",
        "        super(ValDatasetFromFolder, self).__init__()\n",
        "        self.upscale_factor = upscale_factor\n",
        "        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        hr_image = Image.open(self.image_filenames[index])\n",
        "        w, h = hr_image.size\n",
        "        crop_size = calculate_valid_crop_size(min(w, h), self.upscale_factor)\n",
        "        lr_scale = Resize(crop_size // self.upscale_factor, interpolation=Image.BICUBIC)\n",
        "        hr_scale = Resize(crop_size, interpolation=Image.BICUBIC)\n",
        "        hr_image = CenterCrop(crop_size)(hr_image)\n",
        "        lr_image = lr_scale(hr_image)\n",
        "        hr_restore_img = hr_scale(lr_image)\n",
        "        return ToTensor()(lr_image), ToTensor()(hr_restore_img), ToTensor()(hr_image)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "\n",
        "class TestDatasetFromFolder(Dataset):\n",
        "    def __init__(self, dataset_dir, upscale_factor):\n",
        "        super(TestDatasetFromFolder, self).__init__()\n",
        "        self.lr_path = dataset_dir + '/SRF_' + str(upscale_factor) + '/data/'\n",
        "        self.hr_path = dataset_dir + '/SRF_' + str(upscale_factor) + '/target/'\n",
        "        self.upscale_factor = upscale_factor\n",
        "        self.lr_filenames = [join(self.lr_path, x) for x in listdir(self.lr_path) if is_image_file(x)]\n",
        "        self.hr_filenames = [join(self.hr_path, x) for x in listdir(self.hr_path) if is_image_file(x)]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_name = self.lr_filenames[index].split('/')[-1]\n",
        "        lr_image = Image.open(self.lr_filenames[index])\n",
        "        w, h = lr_image.size\n",
        "        hr_image = Image.open(self.hr_filenames[index])\n",
        "        hr_scale = Resize((self.upscale_factor * h, self.upscale_factor * w), interpolation=Image.BICUBIC)\n",
        "        hr_restore_img = hr_scale(lr_image)\n",
        "        return image_name, ToTensor()(lr_image), ToTensor()(hr_restore_img), ToTensor()(hr_image)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.lr_filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgr0F6vldlcC"
      },
      "source": [
        "torch.autograd.set_detect_anomaly(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9gCiSoBdnXC"
      },
      "source": [
        "UPSCALE_FACTOR = 4\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re2-OAGQv-aQ"
      },
      "source": [
        "train_set = TrainDatasetFromFolder('DIV2K_train_HR', crop_size=CROP_SIZE, upscale_factor=UPSCALE_FACTOR)\n",
        "train_loader = DataLoader(dataset=train_set, num_workers=4, batch_size=64, shuffle=True)\n",
        "\n",
        "val_set = ValDatasetFromFolder('DIV2K_valid_HR', upscale_factor=UPSCALE_FACTOR)\n",
        "val_loader = DataLoader(dataset=val_set, num_workers=4, batch_size=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkrlPMHK0Bx-"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA8VHoPTwMaz"
      },
      "source": [
        "from torch import nn, optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQGAwDSGwUnE"
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, kernel_size=3, n_channels=64):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        # The first convolutional block\n",
        "        self.conv_block1 = ConvolutionalBlock(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size,\n",
        "                                              batch_norm=True, activation='PReLu')\n",
        "\n",
        "        # The second convolutional block\n",
        "        self.conv_block2 = ConvolutionalBlock(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size,\n",
        "                                              batch_norm=True, activation=None)\n",
        "\n",
        "    def forward(self, input):\n",
        "        residual = input \n",
        "        output = self.conv_block1(input)\n",
        "        output = self.conv_block2(output)\n",
        "        output = output + residual\n",
        "\n",
        "        return output\n",
        "    \n",
        "class ConvolutionalBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, batch_norm=False, activation=None):\n",
        "        super(ConvolutionalBlock, self).__init__()\n",
        "\n",
        "        if activation is not None:\n",
        "            activation = activation.lower()\n",
        "            assert activation in {'prelu', 'leakyrelu', 'tanh', 'relu'}\n",
        "\n",
        "        layers = list()\n",
        "        layers.append(\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                      padding=kernel_size // 2))\n",
        "\n",
        "        if batch_norm is True:\n",
        "            layers.append(nn.BatchNorm2d(num_features=out_channels))\n",
        "\n",
        "        if activation == 'prelu':\n",
        "            layers.append(nn.PReLU())\n",
        "        elif activation == 'leakyrelu':\n",
        "            layers.append(nn.LeakyReLU(0.2))\n",
        "        elif activation == 'tanh':\n",
        "            layers.append(nn.Tanh())\n",
        "        elif activation == 'relu':\n",
        "            layers.append(nn.ReLU())\n",
        "\n",
        "        self.conv_block = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.conv_block(input)\n",
        "\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNpcnPmbw6QQ"
      },
      "source": [
        "class InterpolateUpsampleBlock(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_channels: int, kernel_size: int=3, stride: int=1, padding: int=1):\n",
        "        super(InterpolateUpsampleBlock, self).__init__()\n",
        "        \n",
        "        self.conv = nn.Conv2d(n_channels, n_channels, kernel_size=kernel_size, \n",
        "                            stride=stride, padding=padding)\n",
        "   \n",
        "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
        "        return F.leaky_relu(self.conv(F.interpolate(input, scale_factor=2, mode=\"bilinear\", align_corners=True)), 0.2, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZnfl5c0uzUI"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, large_kernel_size=9, small_kernel_size=3, n_channels=64, n_blocks=16, scaling_factor=4):\n",
        "        super(Generator, self).__init__()\n",
        "        \n",
        "        assert type(scaling_factor) is int and scaling_factor in [2, 4, 8]\n",
        "\n",
        "        self.conv_block1 = ConvolutionalBlock(in_channels=3, out_channels=n_channels, kernel_size=large_kernel_size,\n",
        "                                              batch_norm=False, activation='PReLu')\n",
        "\n",
        "        self.residual_blocks = nn.Sequential(\n",
        "            *[ResidualBlock(kernel_size=small_kernel_size, n_channels=n_channels) for i in range(n_blocks)])\n",
        "\n",
        "        self.conv_block2 = ConvolutionalBlock(in_channels=n_channels, out_channels=n_channels,\n",
        "                                              kernel_size=small_kernel_size,\n",
        "                                              batch_norm=True, activation=None)\n",
        "\n",
        "        n_upsample_blocks = int(math.log2(scaling_factor))\n",
        "        self.upsample_blocks = nn.Sequential(\n",
        "            *[InterpolateUpsampleBlock(kernel_size=small_kernel_size, n_channels=n_channels) for i\n",
        "              in range(n_upsample_blocks)])\n",
        "\n",
        "        self.conv_block3 = ConvolutionalBlock(in_channels=n_channels, out_channels=3, kernel_size=large_kernel_size,\n",
        "                                              batch_norm=False, activation='Tanh')\n",
        "\n",
        "    def forward(self, lr_imgs):\n",
        "        output = self.conv_block1(lr_imgs) \n",
        "        residual = output \n",
        "        output = self.residual_blocks(output)\n",
        "        output = self.conv_block2(output)\n",
        "        output = output + residual  \n",
        "        output = self.upsample_blocks(output)\n",
        "        sr_imgs = self.conv_block3(output)\n",
        "\n",
        "        return sr_imgs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue5xbeyUuzWF"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(512, 1024, kernel_size=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(1024, 1, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        return torch.sigmoid(self.net(x).view(batch_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7IoZNki0QUR"
      },
      "source": [
        "Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKD-vlkTxe0F"
      },
      "source": [
        "from torchvision.models.vgg import vgg16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RamJwy7yxitq"
      },
      "source": [
        "class TVLoss(nn.Module):\n",
        "  def __init__(self, tv_loss_weight=1):\n",
        "    super(TVLoss, self).__init__()\n",
        "    self.tv_loss_weight=tv_loss_weight\n",
        "  def forward(self, x):\n",
        "    batch_size=x.size()[0]\n",
        "    h_x = x.size()[2]\n",
        "    w_x = x.size()[3]\n",
        "\n",
        "    count_h = self.tensor_size(x[:, :, 1:, :])\n",
        "    count_w = self.tensor_size(x[:, :, :, 1:])\n",
        "\n",
        "    h_tv = torch.pow(x[:, :, 1:, :] - x[:, :, :h_x - 1, :], 2).sum()\n",
        "    w_tv = torch.pow(x[:, :, :, 1:] - x[:, :, :, :w_x - 1], 2).sum()\n",
        "    return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n",
        "\n",
        "  @staticmethod \n",
        "  def tensor_size(t):\n",
        "    return t.size()[1] * t.size()[2] * t.size()[3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiwFaF3tySU_"
      },
      "source": [
        "class GeneratorLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GeneratorLoss, self).__init__()\n",
        "        vgg = vgg16(pretrained=True)\n",
        "        loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n",
        "        for param in loss_network.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.loss_network = loss_network\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "        self.tv_loss = TVLoss()\n",
        "\n",
        "    def forward(self, out_labels, out_images, target_images):\n",
        "        # Adversarial Loss\n",
        "        adversarial_loss = torch.mean(1 - out_labels)\n",
        "        # Perception Loss\n",
        "        perception_loss = self.mse_loss(self.loss_network(out_images), self.loss_network(target_images))\n",
        "        # Image Loss\n",
        "        image_loss = self.mse_loss(out_images, target_images)\n",
        "        # TV Loss\n",
        "        tv_loss = self.tv_loss(out_images)\n",
        "        return image_loss + 0.001 * adversarial_loss + 0.006 * perception_loss + 2e-8 * tv_loss-8 * tv_loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypaozbez01Ee"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from math import exp, log10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kTMGlTD04AY"
      },
      "source": [
        "def gaussian(window_size, sigma):\n",
        "    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n",
        "    return gauss / gauss.sum()\n",
        "\n",
        "\n",
        "def create_window(window_size, channel):\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
        "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
        "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
        "    return window\n",
        "\n",
        "\n",
        "def _ssim(img1, img2, window, window_size, channel, size_average=True):\n",
        "    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n",
        "    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n",
        "\n",
        "    mu1_sq = mu1.pow(2)\n",
        "    mu2_sq = mu2.pow(2)\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "\n",
        "    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n",
        "    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n",
        "\n",
        "    C1 = 0.01 ** 2\n",
        "    C2 = 0.03 ** 2\n",
        "\n",
        "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "    if size_average:\n",
        "        return ssim_map.mean()\n",
        "    else:\n",
        "        return ssim_map.mean(1).mean(1).mean(1)\n",
        "\n",
        "\n",
        "class SSIM(torch.nn.Module):\n",
        "    def __init__(self, window_size=11, size_average=True):\n",
        "        super(SSIM, self).__init__()\n",
        "        self.window_size = window_size\n",
        "        self.size_average = size_average\n",
        "        self.channel = 1\n",
        "        self.window = create_window(window_size, self.channel)\n",
        "\n",
        "    def forward(self, img1, img2):\n",
        "        (_, channel, _, _) = img1.size()\n",
        "\n",
        "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
        "            window = self.window\n",
        "        else:\n",
        "            window = create_window(self.window_size, channel)\n",
        "\n",
        "            if img1.is_cuda:\n",
        "                window = window.cuda(img1.get_device())\n",
        "            window = window.type_as(img1)\n",
        "\n",
        "            self.window = window\n",
        "            self.channel = channel\n",
        "\n",
        "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
        "\n",
        "\n",
        "def ssim(img1, img2, window_size=11, size_average=True):\n",
        "    (_, channel, _, _) = img1.size()\n",
        "    window = create_window(window_size, channel)\n",
        "\n",
        "    if img1.is_cuda:\n",
        "        window = window.cuda(img1.get_device())\n",
        "    window = window.type_as(img1)\n",
        "\n",
        "    return _ssim(img1, img2, window, window_size, channel, size_average)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzzSCJjjy7I9"
      },
      "source": [
        "device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oGBnX7PLGJ-"
      },
      "source": [
        "netG = Generator(UPSCALE_FACTOR)\n",
        "print('# generator parameters:', sum(param.numel() for param in netG.parameters()))\n",
        "netD = Discriminator()\n",
        "print('# discriminator parameters:', sum(param.numel() for param in netD.parameters()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n39cIDQeLJFO"
      },
      "source": [
        "generator_criterion = GeneratorLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ynXcO-8LSgN"
      },
      "source": [
        "generator_criterion = generator_criterion.to(device)\n",
        "netG = netG.to(device)\n",
        "netD = netD.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDlYj1loLiD_"
      },
      "source": [
        "optimizerG = optim.Adam(netG.parameters(), lr=0.001)\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doBMeLWOLs_0"
      },
      "source": [
        "results = {'d_loss': [],\n",
        "           'g_loss': [],\n",
        "           'd_score': [],\n",
        "           'g_score': [],\n",
        "           'psnr': [],\n",
        "           'ssim': []}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeTxlp0eML1d"
      },
      "source": [
        "N_EPOCHS = 50 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNvQ41qkJ7Rk"
      },
      "source": [
        "os.mkdir('epochs')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHadZtxcMO01"
      },
      "source": [
        "for epoch in range(1, N_EPOCHS + 1):\n",
        "        train_bar = tqdm(train_loader)\n",
        "        running_results = {'batch_sizes': 0, 'd_loss': 0, 'g_loss': 0, 'd_score': 0, 'g_score': 0}\n",
        "    \n",
        "        netG.train()\n",
        "        netD.train()\n",
        "        for data, target in train_bar:\n",
        "            g_update_first = True\n",
        "            batch_size = data.size(0)\n",
        "            running_results['batch_sizes'] += batch_size\n",
        "    \n",
        "            ############################\n",
        "            # (1) Update D network: maximize D(x)-1-D(G(z))\n",
        "            ###########################\n",
        "            real_img = Variable(target)\n",
        "            if torch.cuda.is_available():\n",
        "                real_img = real_img.cuda()\n",
        "            z = Variable(data)\n",
        "            if torch.cuda.is_available():\n",
        "                z = z.cuda()\n",
        "            fake_img = netG(z)\n",
        "    \n",
        "            netD.zero_grad()\n",
        "            real_out = netD(real_img).mean()\n",
        "            fake_out = netD(fake_img).mean()\n",
        "            d_loss = 1 - real_out + fake_out\n",
        "            d_loss.backward(retain_graph=True)\n",
        "            optimizerD.step()\n",
        "    \n",
        "            ############################\n",
        "            # (2) Update G network: minimize 1-D(G(z)) + Perception Loss + Image Loss + TV Loss\n",
        "            ###########################\n",
        "            netG.zero_grad()\n",
        "            ## The two lines below are added to prevent runetime error in Google Colab ##\n",
        "            fake_img = netG(z)\n",
        "            fake_out = netD(fake_img).mean()\n",
        "            ##\n",
        "            g_loss = generator_criterion(fake_out, fake_img, real_img)\n",
        "            g_loss.backward()\n",
        "            \n",
        "            fake_img = netG(z)\n",
        "            fake_out = netD(fake_img).mean()\n",
        "            \n",
        "            \n",
        "            optimizerG.step()\n",
        "\n",
        "            # loss for current batch before optimization \n",
        "            running_results['g_loss'] += g_loss.item() * batch_size\n",
        "            running_results['d_loss'] += d_loss.item() * batch_size\n",
        "            running_results['d_score'] += real_out.item() * batch_size\n",
        "            running_results['g_score'] += fake_out.item() * batch_size\n",
        "    \n",
        "            train_bar.set_description(desc='[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f' % (\n",
        "                epoch, N_EPOCHS, running_results['d_loss'] / running_results['batch_sizes'],\n",
        "                running_results['g_loss'] / running_results['batch_sizes'],\n",
        "                running_results['d_score'] / running_results['batch_sizes'],\n",
        "                running_results['g_score'] / running_results['batch_sizes']))\n",
        "    \n",
        "        netG.eval()\n",
        "        out_path = 'training_results/DIV2K_' + str(UPSCALE_FACTOR) + '/'\n",
        "        if not os.path.exists(out_path):\n",
        "            os.makedirs(out_path)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            val_bar = tqdm(val_loader)\n",
        "            valing_results = {'mse': 0, 'ssims': 0, 'psnr': 0, 'ssim': 0, 'batch_sizes': 0}\n",
        "            val_images = []\n",
        "            for val_lr, val_hr_restore, val_hr in val_bar:\n",
        "                batch_size = val_lr.size(0)\n",
        "                valing_results['batch_sizes'] += batch_size\n",
        "                lr = val_lr\n",
        "                hr = val_hr\n",
        "                if torch.cuda.is_available():\n",
        "                    lr = lr.cuda()\n",
        "                    hr = hr.cuda()\n",
        "                sr = netG(lr)\n",
        "        \n",
        "                batch_mse = ((sr - hr) ** 2).data.mean()\n",
        "                valing_results['mse'] += batch_mse * batch_size\n",
        "                batch_ssim = ssim(sr, hr).item()\n",
        "                valing_results['ssims'] += batch_ssim * batch_size\n",
        "                valing_results['psnr'] = 10 * log10((hr.max()**2) / (valing_results['mse'] / valing_results['batch_sizes']))\n",
        "                valing_results['ssim'] = valing_results['ssims'] / valing_results['batch_sizes']\n",
        "                val_bar.set_description(\n",
        "                    desc='[converting LR images to SR images] PSNR: %.4f dB SSIM: %.4f' % (\n",
        "                        valing_results['psnr'], valing_results['ssim']))\n",
        "        \n",
        "                val_images.extend(\n",
        "                    [display_transform()(val_hr_restore.squeeze(0)), display_transform()(hr.data.cpu().squeeze(0)),\n",
        "                     display_transform()(sr.data.cpu().squeeze(0))])\n",
        "            val_images = torch.stack(val_images)\n",
        "            val_images = torch.chunk(val_images, val_images.size(0) // 15)\n",
        "            val_save_bar = tqdm(val_images, desc='[saving training results]')\n",
        "            index = 1\n",
        "            for image in val_save_bar:\n",
        "                image = utils.make_grid(image, nrow=3, padding=5)\n",
        "                utils.save_image(image, out_path + 'epoch_%d_index_%d.png' % (epoch, index), padding=5)\n",
        "                index += 1\n",
        "    \n",
        "        # save model parameters\n",
        "        torch.save(netG.state_dict(), 'epochs/netG_epoch_%d_%d.pth' % (UPSCALE_FACTOR, epoch))\n",
        "        torch.save(netD.state_dict(), 'epochs/netD_epoch_%d_%d.pth' % (UPSCALE_FACTOR, epoch))\n",
        "        # save loss\\scores\\psnr\\ssim\n",
        "        results['d_loss'].append(running_results['d_loss'] / running_results['batch_sizes'])\n",
        "        results['g_loss'].append(running_results['g_loss'] / running_results['batch_sizes'])\n",
        "        results['d_score'].append(running_results['d_score'] / running_results['batch_sizes'])\n",
        "        results['g_score'].append(running_results['g_score'] / running_results['batch_sizes'])\n",
        "        results['psnr'].append(valing_results['psnr'])\n",
        "        results['ssim'].append(valing_results['ssim'])\n",
        "    \n",
        "        if epoch % 1 == 0 and epoch != 0:\n",
        "            out_path = 'statistics/'\n",
        "            data_frame = pd.DataFrame(\n",
        "                data={'Loss_D': results['d_loss'], 'Loss_G': results['g_loss'], 'Score_D': results['d_score'],\n",
        "                      'Score_G': results['g_score'], 'PSNR': results['psnr'], 'SSIM': results['ssim']},\n",
        "                index=range(1, epoch + 1))\n",
        "            data_frame.to_csv(out_path + 'srf_' + str(UPSCALE_FACTOR) + '_train_results.csv', index_label='Epoch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PMlxgfc79m1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXHpL3mPX5Kh"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "from skimage.metrics import peak_signal_noise_ratio as PSNR\n",
        "from skimage.metrics import structural_similarity as SSIM\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV9-WBM2bgS_"
      },
      "source": [
        "n_blocks = 16\n",
        "upscale_factor = 4\n",
        "\n",
        "model = Generator(n_blocks=n_blocks, scaling_factor=upscale_factor)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZcg6tuHbjpk"
      },
      "source": [
        "srgan_checkpoint = \"SRGAN_16blocks_4x.pth\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjkQBa_HmZAF"
      },
      "source": [
        "model.load_state_dict(torch.load(srgan_checkpoint))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1e_8Z19r-u8"
      },
      "source": [
        "def create_data_lists(test_folders, min_size, output_folder):\n",
        "\n",
        "    print(\"\\nCreating data lists... this may take some time.\\n\")\n",
        "\n",
        "    for d in test_folders:\n",
        "        test_images = list()\n",
        "        test_name = d.split(\"/\")[-1]\n",
        "        for i in os.listdir(d):\n",
        "            img_path = os.path.join(d, i)\n",
        "            img = Image.open(img_path, mode='r')\n",
        "            if img.width >= min_size and img.height >= min_size:\n",
        "                test_images.append(img_path)\n",
        "        print(\"There are %d images in the %s test data.\\n\" % (len(test_images), test_name))\n",
        "        with open(os.path.join(output_folder, test_name + '_test_images.json'), 'w') as j:\n",
        "            json.dump(test_images, j)\n",
        "\n",
        "    print(\"JSONS containing lists of Train and Test images have been saved to %s\\n\" % output_folder)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu6VWtEdmbge"
      },
      "source": [
        "with open('./jsons/DIV2K_valid_HR_test_images.json', 'rt') as f:\n",
        "    test_images = json.loads(f.read())\n",
        "\n",
        "save_folder = './jsons/'\n",
        "\n",
        "create_data_lists(\n",
        "    test_folders=['../datasets/DIV2K/DIV2K_valid_HR'],\n",
        "    min_size=257,\n",
        "    output_folder=save_folder\n",
        ")\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVok2q03mds0"
      },
      "source": [
        "downscale_multiplier = 4 # Factor by which we reduce the image\n",
        "\n",
        "img_path = random.choice(test_images)\n",
        "hr_img = Image.open(img_path, mode=\"r\").convert('RGB')\n",
        "lr_img = hr_img.resize((hr_img.width//downscale_multiplier, hr_img.height//downscale_multiplier), Image.BICUBIC)\n",
        "lr_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jr4TpGemdjq"
      },
      "source": [
        "# image super resolution with conventional bicubic interpolation\n",
        "bicubic_img = lr_img.resize((lr_img.width*4, lr_img.height*4), Image.BICUBIC)\n",
        "\n",
        "# image super resolution wwith NN\n",
        "sr_img = model(convert_image(lr_img, source='pil', target='imagenet-norm').unsqueeze(0).to(device))\n",
        "sr_img = torch.clamp(sr_img.squeeze(0).cpu().detach(),-1,1)\n",
        "sr_img = convert_image(sr_img, source='[-1, 1]', target='pil')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys91pTmTm8RR"
      },
      "source": [
        "bicubic_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duSE5udom8Kr"
      },
      "source": [
        "sr_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EA3Jfrfm_dt"
      },
      "source": [
        "image_paths='images/'\n",
        "if (os.path.exists(image_paths)==False):\n",
        "  os.mkdir(image_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRARLEypnA-C"
      },
      "source": [
        "lr_img.save('./images/lr_image.png')\n",
        "bicubic_img.save('./images/bicubic_image.png')\n",
        "sr_img.save('./images/sr_image.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_Ga9yilnDdY"
      },
      "source": [
        "\n",
        "sr_img_y = convert_to_y_channel(sr_img)\n",
        "bicubic_y = convert_to_y_channel(bicubic_img)\n",
        "hr_img_y = convert_to_y_channel(hr_img)\n",
        "\n",
        "print('structure similarity on super resolution image:', SSIM(sr_img_y, hr_img_y, data_range=255.))\n",
        "print('structure similarity on bicubic interpolation image:', SSIM(bicubic_y, hr_img_y, data_range=255.))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}